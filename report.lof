\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The dorsal and ventral pathway in the brain\nobreakspace {}\cite {lehky2007comparison}. The dorsal stream (blue) arrives to the parietal lobe, whereas the ventral pathway (red) reaches the inferotemporal (IT) cortex in the temporal lobe.\relax }}{15}
\contentsline {figure}{\numberline {2.2}{\ignorespaces IT Single-Unit Properties and Their Relationship to Population Performance\nobreakspace {}\cite {dicarlo2012does}. (A) Poststimulus spike histogram from an example IT neuron to one object image (a chair) that was the most effective among 213 tested object images (Zoccolan et al., 2007). (B) Left: the mean responses of the same IT neuron to each of 213 object images (based on spike rate in the gray time window in A). Object images are ranked according to their effectiveness in driving the neuron. As is typical, the neuron responded strongly to ∼10\% of objects images (four example images of nearly equal effectiveness are shown) and was suppressed below background rate by other objects (two example images shown), with no obvious indication of what critical features triggered or suppressed its firing. Colors indicate highly effective (red), medium-effective (blue), and poorly effective (green) images. Right: data from a second study (new IT neuron) using natural images patches to illustrate the same point (Rust and DiCarlo, unpublished). (C) Response profiles from an example IT neuron obtained by varying the position (elevation) of three objects with high (red), medium (blue), and (low) effectiveness. While response magnitude is not preserved, the rank-order object identity preference is maintained along the entire tested range of tested positions. (D) To explain data in (C), each IT neuron (right panel) is conceptualized as having joint, separable tuning for shape (identity) variables and for identity-preserving variables (e.g., position). If a population of such IT neurons tiles that space of variables (left panel), the resulting population representation conveys untangled object identity manifolds (Figure 2B, right), while still conveying information about other variables such as position, size, etc. (Li et al., 2009). (E) Direct tests of untangled object identity manifolds consist of using simple decoders (e.g., linear classifiers) to measure the cross-validated population performance on categorization tasks (adapted from Hung et al., 2005 and Rust and DiCarlo, 2010). Performance magnitude approaches ceiling level with only a few hundred neurons (left panel), and the same population decode gives nearly perfect generalization across moderate changes in position (1.5 deg and 3 deg shifts), scale (0.5×/2× and 0.33×/3×), and context (right panel), which is consistent with previous work (Hung et al., 2005; right bar) and with the simulations in (D).\relax }}{18}
\contentsline {figure}{\numberline {2.3}{\ignorespaces The ventral visual pathway and its hierarchical organization\nobreakspace {}\cite {dicarlo2012does}. (A) Ventral stream cortical area locations in the macaque monkey brain, and flow of visual information from the retina. (B) Each area is plotted so that its size is proportional to its cortical surface area (Felleman and Van Essen, 1991). Approximate total number of neurons (both hemispheres) is shown in the corner of each area (M = million). The approximate dimensionality of each representation (number of projection neurons) is shown above each area, based on neuronal densities (Collins et al., 2010), layer 2/3 neuronal fraction (O'Kusky and Colonnier, 1982), and portion (color) dedicated to processing the central 10 deg of the visual field (Brewer et al., 2002). Approximate median response latency is listed on the right (Nowak and Bullier, 1997 and Schmolesky et al., 1998).\relax }}{21}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Receptive field (RF) sizes along the ventral cortical stream in the primate. While the degree of complexity of processing may increase, the RF size at any one eccentricity also increases dramatically along the various cortical areas from V1 into the temporal pole. The circles shown in the figure are not drawn to scale, but the numbers above the circles indicate approximate relative sizes of the RF diameters.\nobreakspace {}\cite {vidyasagar2013reading}.\relax }}{23}
\contentsline {figure}{\numberline {2.5}{\ignorespaces The hierarchical ventral stream and the corresponding tuned features for each layer\nobreakspace {}\cite {serre2010neuromorphic}.\relax }}{24}
\contentsline {figure}{\numberline {2.6}{\ignorespaces A. The inset shows an example of a neuronal action potential. The action potential is a short voltage pulse of 1-2ms duration and 100mV of amplituted. B. Signal transmition from a presynaptic neuron j to a post synaptic neuron i. The synapse is marked by a dashed circle \cite {gernstbook}.\relax }}{26}
\contentsline {figure}{\numberline {2.7}{\ignorespaces The membrane potential is increased and at time tj(f) the membrane potential reaches the threshold so a spike is emmited \cite {pnn}.\relax }}{28}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Excitatory postsynaptic potential (EPSP) and Inhibitory postsynaptic potential (IPSP) of a biological neuron \cite {Maass97networksof}.\relax }}{28}
\contentsline {figure}{\numberline {2.9}{\ignorespaces The Leaky Integrate-and-fire model. (a) The RC circuit diagram of the model. When the membrane potential reaches a threshold voltage ${\theta }$, the neuron is considered to have fired a spike and the switch closes. The aforementioned short-circuit causes the membrane potential to return back to the resting membrane potential E$_{m}$. (b) Response of LIF circuit to current injection. The refractory period can be observed directly after the firing of a spike \cite {sterratt2011principles}.\relax }}{30}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Encoding with Gaussian Receptive Fields. The horizontal axis represents the real input data, the vertical axis represent the firing times of the input neurons to an input value 0.3 \cite {Meftah:2010:SED:1873252.1873282}. \relax }}{32}
\contentsline {figure}{\numberline {2.11}{\ignorespaces The weights are changing only if the firing times of neurons j and i are close to each other. Data taken from the experiments of Bi and Poo \cite {bigpoo}. \relax }}{34}
\contentsline {figure}{\numberline {2.12}{\ignorespaces The exponential learning window as a function the difference between the presynaptic and the postsynaptic firing times. A$_{+}$=1, A$_{-}$=-1, $\tau _{1}$=10ms, $\tau _{2}$=20ms \cite {gernstbook}. \relax }}{34}
\contentsline {figure}{\numberline {2.13}{\ignorespaces System overview of the dynamic hand posture recognition platform. \relax }}{36}
\contentsline {figure}{\numberline {2.14}{\ignorespaces SpiNNaker system diagram. Each element represents one chip with local memory. Every chip connects to its neighbours through the six bi-directional on-board links. \relax }}{37}
\contentsline {figure}{\numberline {2.15}{\ignorespaces Neuromorphic platform for sound localisation: a silicon cochlea connects to a 48-node SpiNNaker board via a FPGA.\relax }}{39}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Each individual neuron in the convolution layer (right matrix) connects to its receptive field using the same kernel. The value of the kernel is represented by the synaptic weights between the connected neurons.\relax }}{40}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Model 1. The retina input is convolved with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The templates are considered as convolution kernels in the last layer. The WTA circuit can be used as an option to show the template matching result more clearly. \relax }}{41}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Templates of the five postures: `Fist',`Index Finger', `Victory Sign', `Full Hand' and `Thumb up'.\relax }}{41}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Real parts of the Gabor filters orienting four directions.\relax }}{42}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Model 2. The retina input convolves with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The following tracking layer finds the most active area of some fixed size, moves the posture to the centre and pushes the image to the trained MLP. The winner-take-all (WTA) layer can be used as an option to show the template matching result more clearly.\relax }}{43}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Neural responses with time of four experiments to the same recorded moving postures. The recognition output is normalised to \unhbox \voidb@x \hbox {[-1, 1]}. Every point represents the highest response in a specific population (different colour) for a 30\nobreakspace {}ms frame. The 1st plot refers to Model 1 with the full input resolution, and the 2nd plot Model 1 with the sub-sampled input resolution; and the 3rd and fourth plots both refer to Model 2, and with high and low input resolution respectively. \relax }}{45}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Snapshots of the real-time dynamic posture recognition system on SpiNNaker. \relax }}{50}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Real-time neural responses of two experiments on SpiNNaker with time to the same recorded postures. These two experiments only differ in input resolution. The result of the high input resolution test is plotted the first with a sample frame of 30\nobreakspace {}ms; while the 3rd plot shows the same result with a sample frame of 300\nobreakspace {}ms. The other two plots refer to the smaller input resolution. Every point represents the over all number of spikes of a specific population (different colour) in a `frame'. \relax }}{51}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Spikes captured during the live recognition of the recorded retinal input with the resolution of 128$\times $128. \relax }}{53}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Spikes captured during the live recognition of the recorded retinal input with the resolution of 32$\times $32. \relax }}{54}
\addvspace {10\p@ }
