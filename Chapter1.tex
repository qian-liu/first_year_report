\chapter{Introduction}
\label{cha:intro}
The hypothesis of the research is to model the primate visual pathway in the brain with spiking neurons running on SpiNNaker.
The previous studies on visual pathway modelling is limited on the spiking neural network simulators (computational power, scalability, and simulation time).
Thus, using spiking neurons is a step towards biological simulations.

Patterns or objects in two-dimensional images can be described with four properties~\cite{wysoski2008fast}: position, geometry (i.e. size, area and shape), colour/texture, and trajectory. 
Appearance-based methods are the most direct approach to performing pattern recognition where the test image is compared with a set of templates to find the best match for an individual or combination of properties. 
%In terms of classification algorithms, distance measure methods (nearest neighbour, k-means clustering), support vector machine (SVM), multi-layer perceptron (MLP) neural networks and statistical methods, e.g. Gaussian mixture model (GMM) have been applied successfully in visual recognition. 
However, the 2D projection of an object changes under different conditions including illumination, viewing angles, relative positions and distance, making it virtually impossible to represent all appearances of an object. 
To improve reliability, robustness and classification efficiency, approaches such as edge matching~\cite{canny1986computational}, divide-and-conquer~\cite{toygar2004multiple}, gradient matching~\cite{wei2006robust} and feature based methods~\cite{lowe2004distinctive, bay2008speeded} are used.
%Moreover, feature based methods are used to improve reliability, robustness and classification efficiency. 
%Among various feature extraction methods, the scale-invariant feature transform (SIFT)~\cite{lowe2004distinctive} and the sped-up robust features (SURF)~\cite{bay2008speeded} methods are well-accepted recently in the field. 
In computer vision and image processing, features can be specific structures in the image such as points, edges or objects; and also may be a general neighborhood operation or feature detection applied to the image.
Finding an appropriate feature for a specific object still remains an open question and there is no process as general, accurate, or energy-efficient as that demonstrated by the brain.
It is not a new idea to turn to nature for inspiration. 
%Turning to biology for answers is always the way to explore the field of visual pattern recognition. 
Riesenhuber et al.~\cite{riesenhuber1999hierarchical}, for instance, presented a biologically-inspired model based on the organisation of the visual cortex which has the ability to represent relative position- and scale-invariant features.
Integrating a rich set of visual features became possible using a feed-forward hierarchical pathway. 

\section{What Is Object Recognition?}
\label{sec:aim}
Object recognition is the process of assigning labels to particular objects, ranging from precise labels (`identification') to coarse labels (`categorisation')~\cite{dicarlo2012does}.
This includes the ability to accomplish these tasks under various identity-preserving transformations such as object position, scale, viewing angle, background clutter, etc.

The brain can accurately recognise and categorise objects remarkably quickly, for example object recognition time in monkeys is under 200~ms~\cite{fabre1998rapid} and the images are presented sequentially in spikes less than 100~ms along the visual pathway~\cite{keysers2001speed}.
This research focuses on this rapid and highly accurate object recognition, `core recognition', which is defined by DiCarlo and Cox~\cite{dicarlo2007untangling}.


\section{Why Is It Important?}
\label{sec:imp}
The human brain recognises huge amount of objects rapidly with ease even in cluttered and natural scenes.
This robust object recognition of the biological system is invariant to the change of position, scale, viewing angle and etc. (known as transformation invariance).
While the major stumbling problem of the computer object recognition lies in the poor robustness to the transformations.
Each encounter of an object on the retina is unique because of differing illumination (lighting conditions), position (projection locations on the retina), scale (distances and sizes), pose (viewing angles), and clutter (visual contexts).
In addition, a difficult specificity-invariance trade-off occurs in the categorisation tasks, since the recognition should be able to discriminate different object classes (intraclass variability) while at the same time remaining tolerant to image transformations.   

Exploring and mimicking invariant object recognition within the brain is a promising approach to tackling the computational difficulty;
in turn it also contributes to understanding biological visual processing by means of mimicking neural activity in the visual system of the brain.
Moreover, energy-efficiency improvements following from the great energy efficiency of biological systems will help in building object recognition systems, e.g. posture recognition for human-machine interfaces in mobile devices.  

\section{How to Mimic The Brain}
\label{sec:brn}
To explore how the brain may recognise objects, we have employed a biologically-inspired DVS silicon retina~\cite{lenero20113}.
This is a good example of low-cost visual processing due to  its event-driven and redundancy-reducing style of computation.
A SpiNNaker machine~\cite{furber2014spinnaker} is also exploited as the back-end of the system, which is a massive parallel computing platform aimed at real-time simulation of Spiking Neural Networks~(SNNs). 
%SpiNNaker, as the back-end of the system, provides a flexible, event-driven mechanism for real-time simulation of SNNs, and is where the posture recogniser locates.
%Thanks to its high-performance massively parallel processing, SpiNNaker makes it possible to simulate large-scale neural networks in real-time.
Thanks to SpiNNaker's high-performance processing of large-scale neural networks, we explore biological approaches to visual processing by mimicking the functions of different layers along the visual pathway. 

Building a real-time recognition system for dynamic hand postures is a first step of exploring visual processing in a biological fashion and is also a validation of the performance of the neuromorphic platform.
%To match the image properties detailed earlier, the position, shape, size and trajectory of the hand postures can be detected from the retina output.
To keep the task simple at first, the postures are of similar size and the goal is to recognise the shape of a hand with moving positions.
This preliminary work achieved the first milestone of the research which aims at building a position-invariant object recognition system exploiting V1-like neurons (primary visual cortex: area V1) to classify five hand postures. 
%Tracking the postures with a short memory will form part of the future work.
\section{Report Structure}
\label{sec:str}
In Chapter~\ref{cha:bkg}, this report starts from the biological aspects of object recognition: the task is mainly processed along the ventral visual pathway with the untangling object representations at different levels of abstraction.
This is followed by the introduction of spiking neural networks to illustrate the abilities of neural modelling from single neurons to populations.
Further, a number of learning algorithms are also discussed together with recognition/classification tasks where they have been successfully applied.
The final part of this chapter describes the details of the hardware neuromorphic system, including the silicon retina and the SpiNNaker platform.

In terms of preliminary work, convolutional neural network models exploiting V1-like neurons are defined and tested in Matlab, and model structures and experimental results are stated in Chapter~\ref{chp:cnn}.
In Chapter~\ref{cha:rsp}, theses rate-based models are converted into spiking neurons, and real-time live object recognition and recorded data experiments are carried out.

Finally, the contribution of this work is summarised and the future directions are outlined in Chapter~\ref{cha:plan}.
