\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Convolutional Neural Networks}{32}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chp:cnn}{{3}{32}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Model Description}{32}}
\newlabel{sec:mdc}{{3.1}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Each individual neuron in the convolution layer (right matrix) connects to its receptive field using the same kernel. The value of the kernel is represented by the synaptic weights between the connected neurons.\relax }}{32}}
\newlabel{fig:conv}{{3.1}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Model 1. The retina input is convolved with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The templates are considered as convolution kernels in the last layer. The WTA circuit can be used as an option to show the template matching result more clearly. \relax }}{33}}
\newlabel{fig:model1}{{3.2}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Templates of the five postures: `Fist',`Index Finger', `Victory Sign', `Full Hand' and `Thumb up'.\relax }}{33}}
\newlabel{fig:template}{{3.3}{33}}
\citation{lecun1998gradient}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Real parts of the Gabor filters orienting four directions.\relax }}{34}}
\newlabel{fig:gabor}{{3.4}{34}}
\newlabel{equ:gabor}{{3.1}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Model 2. The retina input convolves with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The following tracking layer finds the most active area of some fixed size, moves the posture to the centre and pushes the image to the trained MLP. The winner-take-all (WTA) layer can be used as an option to show the template matching result more clearly.\relax }}{35}}
\newlabel{fig:model2}{{3.5}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Experimental Set-up}{35}}
\newlabel{sec:tat}{{3.2}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Experimental Results}{35}}
\newlabel{sec:exp}{{3.3}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Sizes of the convolutional neural networks.\relax }}{36}}
\newlabel{tbl:m1}{{3.1a}{36}}
\newlabel{sub@tbl:m1}{{a}{36}}
\newlabel{tbl:m2}{{3.1b}{36}}
\newlabel{sub@tbl:m2}{{b}{36}}
\newlabel{tbl:nns}{{3.1}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Neural responses with time of four experiments to the same recorded moving postures. The recognition output is normalised to \unhbox \voidb@x \hbox {[-1, 1]}. Every point represents the highest response in a specific population (different colour) for a 30\nobreakspace  {}ms frame. The 1st plot refers to Model 1 with the full input resolution, and the 2nd plot Model 1 with the sub-sampled input resolution; and the 3rd and fourth plots both refer to Model 2, and with high and low input resolution respectively. \relax }}{37}}
\newlabel{fig:matlabrec}{{3.6}{37}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Recognition results using linear perceptrons in \%\relax }}{38}}
\newlabel{tbl:rsl}{{3.2}{38}}
\@setckpt{Chapter3}{
\setcounter{page}{39}
\setcounter{equation}{1}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{2}
\setcounter{lstnumber}{1}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{nlinenum}{0}
\setcounter{parentequation}{8}
\setcounter{lstlisting}{0}
}
